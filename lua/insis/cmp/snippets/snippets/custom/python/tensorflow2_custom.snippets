snippet tf_custom_loss_func "tensorflow custom lossfunction by function" b
        def create_huber(threshold=1.0):
        	def huber_fn(y_true, y_pred):
        		error = y_true - y_pred
        		is_small_error = tf.abs(error) < threshold
        		squared_loss = tf.square(error) / 2
        		linear_loss  = threshold * tf.abs(error) - threshold**2 / 2
        		return tf.where(is_small_error, squared_loss, linear_loss)
        	return huber_fn
        
snippet tf_custom_loss_class "tensorflow custom lossfunction by class" b
        class HuberLoss(keras.losses.Loss):
        	def __init__(self, threshold=1.0, **kwargs):
        		self.threshold = threshold
        		super().__init__(**kwargs)
        
        	def call(self, y_true, y_pred):
        		error = y_true - y_pred
        		is_small_error = tf.abs(error) < self.threshold
        		squared_loss = tf.square(error) / 2
        		linear_loss  = self.threshold * tf.abs(error) - self.threshold**2 / 2
        		return tf.where(is_small_error, squared_loss, linear_loss)
        
        	def get_config(self):
        		base_config = super().get_config()
        		return {**base_config, "threshold": self.threshold}
        
snippet tf_custom_regularizer_func "tensorflow custom regularizer by function" b
        def my_l1_regularizer(weights):
        	return tf.reduce_sum(tf.abs(0.01 * weights))
        
snippet tf_custom_regularizer_class "tensorflow custom regularizer by class" b
        class MyL1Regularizer(keras.regularizers.Regularizer):
        	def __init__(self, factor):
        		self.factor = factor
        	def __call__(self, weights):
        		return tf.reduce_sum(tf.abs(self.factor * weights))
        	def get_config(self):
        		return {"factor": self.factor}
        
snippet tf_custom_initializer_func "tensorflow custom initializer by function" b
        def my_glorot_initializer(shape, dtype=tf.float32):
        	stddev = tf.sqrt(2. / (shape[0] + shape[1]))
        	return tf.random.normal(shape, stddev=stddev, dtype=dtype)
        
snippet tf_custom_activation_func "tensorflow custom activation by function" b
        def my_positive_weights(weights): # return value is just tf.nn.relu(weights)
        	return tf.where(weights < 0., tf.zeros_like(weights), weights)
        
snippet tf_custom_other_func "tensorflow custom other function by function" b
        def my_softplus(z): # return value is just tf.nn.softplus(z)
        	return tf.math.log(tf.exp(z) + 1.0)
        
snippet tf_custom_metrics_func "tensorflow custom metrics by function" b
        def create_huber(threshold=1.0):
        	def huber_fn(y_true, y_pred):
        		error = y_true - y_pred
        		is_small_error = tf.abs(error) < threshold
        		squared_loss = tf.square(error) / 2
        		linear_loss  = threshold * tf.abs(error) - threshold**2 / 2
        		return tf.where(is_small_error, squared_loss, linear_loss)
        	return huber_fn
        
snippet tf_custom_metrics_class "tensorflow custom metrics by class" b
        class HuberMetric(keras.metrics.Mean):
        	def __init__(self, threshold=1.0, name='HuberMetric', dtype=None):
        		self.threshold = threshold
        		self.huber_fn = create_huber(threshold)
        		super().__init__(name=name, dtype=dtype)
        	def update_state(self, y_true, y_pred, sample_weight=None):
        		metric = self.huber_fn(y_true, y_pred)
        		super(HuberMetric, self).update_state(metric, sample_weight)
        	def get_config(self):
        		base_config = super().get_config()
        		return {**base_config, "threshold": self.threshold}
        
snippet tf_custom_metrics_class_plus "tensorflow custom metrics by class" b
        class HuberMetric(keras.metrics.Metric):
        	def __init__(self, threshold=1.0, **kwargs):
        		super().__init__(**kwargs) # handles base args (e.g., dtype)
        		self.threshold = threshold
        		self.huber_fn = create_huber(threshold)
        		self.total = self.add_weight("total", initializer="zeros")
        		self.count = self.add_weight("count", initializer="zeros")
        
        	def huber_fn(self, y_true, y_pred): # workaround
        		error = y_true - y_pred
        		is_small_error = tf.abs(error) < self.threshold
        		squared_loss = tf.square(error) / 2
        		linear_loss  = self.threshold * tf.abs(error) - self.threshold**2 / 2
        		return tf.where(is_small_error, squared_loss, linear_loss)
        
        	def update_state(self, y_true, y_pred, sample_weight=None):
        		metric = self.huber_fn(y_true, y_pred)
        		self.total.assign_add(tf.reduce_sum(metric))
        		self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))
        
        	def result(self):
        		return self.total / self.count
        
        	def get_config(self):
        		base_config = super().get_config()
        		return {**base_config, "threshold": self.threshold}
        
snippet tf_custom_layers_func "tensorflow custom layers by function" b
        exponential_layer = keras.layers.Lambda(lambda x: tf.exp(x))
        
snippet tf_custom_layers_class_plus "tensorflow custom layers by class lite" b
        class MyDense(keras.layers.Layer):
        	def __init__(self, units, activation=None, **kwargs):
        		super().__init__(**kwargs)
        		self.units = units
        		self.activation = keras.activations.get(activation)
        
        	def build(self, batch_input_shape):
        		self.kernel = self.add_weight(
        			name="kernel", shape=[batch_input_shape[-1], self.units],
        			initializer="glorot_normal")
        		self.bias = self.add_weight(
        			name="bias", shape=[self.units], initializer="zeros")
        		super().build(batch_input_shape) # must be at the end
        
        	def call(self, X):
        		return self.activation(X @ self.kernel + self.bias)
        
        	def compute_output_shape(self, batch_input_shape):
        		return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])
        
        	def get_config(self):
        		base_config = super().get_config()
        		return {**base_config, "units": self.units,
        				"activation": keras.activations.serialize(self.activation)}
        
snippet tf_custom_layers_class_lite "tensorflow custom layers by class lite" b
        class MyMultiLayer(keras.layers.Layer):
        	def call(self, X):
        		X1, X2 = X
        		return X1 + X2, X1 * X2
        
        	def compute_output_shape(self, batch_input_shape):
        		batch_input_shape1, batch_input_shape2 = batch_input_shape
        		return [batch_input_shape1, batch_input_shape2]
        
snippet tf_custom_layers_class "tensorflow custom layers by class" b
        class AddGaussianNoise(keras.layers.Layer):
        	def __init__(self, stddev, **kwargs):
        		super().__init__(**kwargs)
        		self.stddev = stddev
        
        	def call(self, X, training=None):
        		if training:
        			noise = tf.random.normal(tf.shape(X), stddev=self.stddev)
        			return X + noise
        		else:
        			return X
        
        	def compute_output_shape(self, batch_input_shape):
        		return batch_input_shape
        
snippet tf_custom_layers_block_class "tensorflow custom layers block by class" b
        class ResidualBlock(keras.layers.Layer):
        	def __init__(self, n_layers, n_neurons, **kwargs):
        		super().__init__(**kwargs)
        		self.n_layers = n_layers
        		self.n_neurons = n_neurons
        		self.hidden = [keras.layers.Dense(n_neurons, activation="elu", kernel_initializer="he_normal")
        			for _ in range(n_layers)]
        
        	def call(self, inputs):
        		Z = inputs
        		for layer in self.hidden:
        			Z = layer(Z)
        		return inputs + Z
        
        	def get_config(self):
        		base_config = super().get_config()
        		return {**base_config,
        				"n_layers": self.n_layers, "n_neurons": self.n_neurons}
        
snippet tf_custom_model_class "tensorflow custom model by class" b
        class ResidualRegressor(keras.models.Model):
        	def __init__(self, output_dim, **kwargs):
        		super().__init__(**kwargs)
        		self.output_dim = output_dim
        		self.hidden1 = keras.layers.Dense(30, activation="elu",
        			kernel_initializer="he_normal")
        		self.block1 = ResidualBlock(2, 30)
        		self.block2 = ResidualBlock(2, 30)
        		self.out = keras.layers.Dense(output_dim)
        
        	def call(self, inputs):
        		Z = self.hidden1(inputs)
        		for _ in range(1 + 3):
        			Z = self.block1(Z)
        		Z = self.block2(Z)
        		return self.out(Z)
        
        	def get_config(self):
        		base_config = super().get_config()
        		return {**base_config,
        				"output_dim": self.output_dim}
        
snippet tf_custom_model_class_plus "tensorflow custom model by class plus" b
        class ReconstructingRegressor(keras.models.Model):
        	def __init__(self, output_dim, **kwargs):
        		super().__init__(**kwargs)
        		self.hidden = [keras.layers.Dense(30, activation="selu", kernel_initializer="lecun_normal")
        			for _ in range(5)]
        		self.out = keras.layers.Dense(output_dim)
        		# TODO: check https://github.com/tensorflow/tensorflow/issues/26260
        		#self.reconstruction_mean = keras.metrics.Mean(name="reconstruction_error")
        
        	def build(self, batch_input_shape):
        		n_inputs = batch_input_shape[-1]
        		self.reconstruct = keras.layers.Dense(n_inputs)
        		super().build(batch_input_shape)
        
        	def call(self, inputs, training=None):
        		Z = inputs
        		for layer in self.hidden:
        			Z = layer(Z)
        		reconstruction = self.reconstruct(Z)
        		recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))
        		self.add_loss(0.05 * recon_loss)
        		#if training:
        		#    result = self.reconstruction_mean(recon_loss)
        		#    self.add_metric(result)
        		return self.out(Z)
        
        	def get_config(self):
        		base_config = super().get_config()
        		return {**base_config,
        				"output_dim": self.output_dim}
